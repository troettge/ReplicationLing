---
title             : "Replication Studies in Linguistics Journals"
shorttitle        : "Preregistration"

author: 
  - name          : "Kristina Kobrock"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "Timo B. Roettger"
    affiliation   : "2"
    role:
      - Writing - Review & Editing

affiliation:
  - id            : "1"
    institution   : "Osnabrueck University"
  - id            : "2"
    institution   : "Konstanz Business School"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction
After the so-called replication crisis has been called out for various disciplines including psychology (Open Science Community, 2015), economics (Camerer et al., 2016), and the social sciences (Camerer et al., 2018), researchers increasingly have to ask themselves whether their scientific discipline is also affected by such an amount of non-reproducible findings in standard literature. This is also true for the field of experimental linguistics. In order to evaluate the replication attempts in this area of research, the here intended study aims to assess the amount and quality of replication studies being published in standard journals of the field. Specifically, the study aims to address the following main research questions: How many replication studies are being published in journals representative for experimental linguistic research? How did their number change over time and what future trend can be expected? Which kinds of replication studies are being published and which factors conribute to their publication?
The intended study consists of two parts: First, with a sample of 100 journals, we will give an overview on replication attempts in the field. Second, we will conduct a more detailed analysis of the replication studies published in 20 journals regarding their contributing factors and quality.

# Overview: Rate of Replication Mention

## Methods
The key dependent variable of the first part of the intended study is the rate of replication mention for journals relevant to the field of experimental linguistics. In order to determine these rates for the individual journals, we will draw on a method introduced by Makel et al. (2012) who used it for the field of psychology. Following their method, we will search the "Web of Science" (webofknowledge.com) for articles containing the search term "replicat*" in title, abstract or keywords. The rate of replication mention for each journal is then calculated by dividing the number of articles containing the search term by the total number of articles published in the respective journal.

### Research Questions
With this part of the study we intend to answer the following research questions: How many replication studies are being published in journals representative for experimental linguistic research? How did their number change over time and what future trend can be expected? Our aim is to present an overview of replication mention by journal on a timescale from 1945 to 2020. Additionally, we are interested in the influence of submission guidelines on the amount of replication studies published in the respective journals.

### Sample
To obtain a representative sample of journals relevant for the field of experimental linguistics, we follow the procedure presented here: First, using the Web of Science advanced search on the "Web of Science Core Collection" database, we filter for the category "Linguistics" (WC=(Linguistics)) that lists the articles of every journal covered by Web of Science that was assigned to the subject category of Linguistics (http://images.webofknowledge.com/WOKRS535R111/help/WOS/hp_subject_category_terms_tasca.html). All English language articles from the full available range of complete years (1945-2020) are taken into account. From the resulting set (159.002) only those articles are selected which contain the search term "experiment\*" in their title, abstract or keywords using TS="experiment\*" as a means to filter for experimental linguistic studies resulting in a set of 11.093 articles. The relevant journals are selected based on the obtained article counts. From all journals that include at least one experimental linguistic study (418), journals with less than 100 linguistically related articles (WC=(Linguistics)) are excluded yielding 259 remaining journals. Because we are interested in journals with a high proportion of experimental studies, we calculate the ratio of experimental studies (TS="experiment\*") by total amount of linguistics related (WC=Linguistics) articles per journal and sort the results in a descending manner. The first 100 journals of this list make up the sample. Please see [osf-link] for the full sample.

### Procedure
The total number of articles published in a journal and the total number of articles containing the search term "replicat\*" are obtained via Web of Science search for the 100 sampled journals and the relevant timespan (1945-2020). These numbers will serve to calculate the rates of replication mention for the respective journals replicating the method used by Makel et al. (2012). The rates of replication mention are computed by dividing the number of articles containing the term "replicat*" by the total number of articles for each journal.
We further examine the journals' submission guidelines adopting the procedure used by Martin and Clarke (2017) who grouped more than one thousand psychology journals into four classes determined by what was stated in the "instructions to authors" and "aims and scope" sections on the websites of the respective journals:
(1) Journals which stated that they accepted replications;
(2) Journals which did not state they accepted replications but did not discourage replications either;
(3) Journals which implicitly discouraged replications through the use of emphasis on the scientific originality of submissions,
(4) Journals which actively discouraged replications by stating explicitly that they did not accept replications for publication.

### Data Analysis
a plot with rates of replication mention for top 10 journals (others grouped), 
a plot with overall rates of replication mention per year, 
a plot with journals belonging to the 4 categories and their rates of replication mention


# Replication Rates and contributing factors

## Methods
The aim of the second part of the study preregistered here is to obtain a better understanding of the underlying mechanisms of replication attempts published in the field of experimental linguistics. Because the term "replication" and its different word forms are commonly used in ambiguous ways, the articles that contain the search term "replicat\*" require further analysis to determine whether the articles in question indeed report a replication study or use the term in a different word sense. We will then be able to refine the rate of replication mention from the first part of the study and give a replication rate instead that captures only real replication attempts. This will be done with a smaller subset of 20 journals. 

### Research Questions
The main research questions addressed with this second part are which kinds of replication studies are being published and which factors conribute to their publication. We would like to find out what types of replication studies are prevalent in the field, i.e. direct, partial or conceptual replications, and what the main changes made to the initial study are. We are further interested in whether journal impact factors, citation counts of the articles, years between publication of the initial study and the replication attempt and the factor open access publication are relevant for explaining the results.

### Sample
From the list of 100 journals obtained above, the first 20 are selected for a more detailed analysis, excluding those for which less than 2 hits can be obtained running a search for the search term "replicat\*" on titles, abstracts and keywords (TS=(replicat\*)). This method yields a total number of 274 articles. Because of the skewed distribution of our sample (114 hits for Journal of Memory and Language, only less than 40 for all other journals), we will randomly select 50 out of the 114 articles for the Journal of Memory and Language to make the sample more comparable.

### Procedure
The sampling procedure above gives us 210 possible self-labeled replication studies. The first step is to identify whether the article indeed presents a replication attempt or not. By reading title and abstract of the paper a first intuition of what the article is about can be obtained. The main task is to investigate whether the authors claim that their underlying aim was to replicate or reproduce findings or methods of an initial study. A search for occurrences of the search term "replicat" in the text and a look at the paragraph before the Methods section and the first paragraph of the Discussion section (following Makel et al. 2016) helps to further identify the intention communicated by the authors regarding a replication attempt. If the authors communicate that (one of) the underlying aim(s) was to replicate an original study, this article can be treated as a replication. It then qualifies for further analysis after the coding scheme that can be viewed here: [osf-link]. Replication rates are calculated for the 20 journals by correcting the rate of replication mention by the ratio of how many articles including the term "replicat*" have indeed been classified as replications. Under the assumption that the authors did not make any severe changes to the initial study without reporting them, number and type of changes made by the replication study are assessed. The replication studies are classified according to three types: direct replication (0 changes), partial replication (1 change) and conceptual replication (2 or more changes). The categories of changes are: experimental paradigm, sample, materials/experimental set-up, dependent variable and independent variable as well as control. We will only check whether a change belonging to one of the categories is made (yes/no) and not the power or number of changes. Coding the articles also involves to examine the factors open access (yes/no), years between initial study and replication attempt, author overlap (yes/no), citation counts of both studies and the language under investigation. The information on whether the article is open access can be obtained from Web of Science as well as citation counts and years of publication for both studies. An author overlap is attested to the studies at hand as soon as even one of the authors contributing to one study was also working on the other study.

### Data Analysis
replication rate by impact factor, open access & policy (submission guidelines)
type by citation original & year

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
